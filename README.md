# Video-Object-Tracking-With-Yolov8

## üìå Project Overview

**YOLO Human Trajectory Visualization** is a computer vision project focused on **tracking the movement paths of multiple individuals** within a video using the **YOLOv8 object detection model**. This system identifies and tracks people across video frames, plots their trajectory paths, and generates a final video that visualizes each individual‚Äôs movement with unique color-coded lines.

### üéØ Main Objectives

- Detect and track **multiple humans** using YOLOv8 in a custom video.
- Assign a unique ID and color to each detected individual.
- Plot and draw the **trajectory path** followed by each person.
- Generate a final **output video** with overlaid paths.
- Optional Bonus: Simultaneous tracking of multiple individuals with different path colors.

---

## üß† Key Features

- ‚úÖ Real-time multi-person tracking using YOLOv8
- ‚úÖ Trajectory plotting using color-coded polylines
- ‚úÖ Custom video processing with frame-by-frame analysis
- ‚úÖ Modular Python implementation for scalability
- ‚úÖ Option to export bounding box data as CSV

---

## üß∞ Tech Stack

| Component            | Technology       |
|---------------------|------------------|
| Language             | Python 3.10      |
| Object Detection     | YOLOv8 (Ultralytics) |
| Data Handling        | NumPy, OpenCV    |
| Video I/O            | OpenCV           |
| Visualization        | Matplotlib, OpenCV |
| Tracking Logic       | Centroid Tracking |
| Environment          | Google Colab / Jupyter Notebook |

---

## üì¶ Installation

Follow these steps to set up the environment:

```bash
# Clone the repository
git clone https://github.com/yourusername/yolo-human-trajectory-visualization.git
cd yolo-human-trajectory-visualization

# Create and activate a virtual environment (optional)
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Install required libraries
pip install -r requirements.txt
```

**If using Google Colab:**

```python
!pip install ultralytics opencv-python-headless matplotlib
```

---

## üß™ How It Works

1. **Load Video**  
   Input a custom video with multiple individuals moving.

2. **Object Detection with YOLOv8**  
   Detect humans frame-by-frame using a pretrained YOLOv8 model.

3. **Track Individuals**  
   Use centroid-based tracking to assign IDs and follow individuals over time.

4. **Trajectory Drawing**  
   Save coordinates and draw paths for each ID using OpenCV polylines.

5. **Export Results**  
   Save the final annotated video and optional CSV path logs.

---

## üîç Sample Output

<img src="https://user-images.githubusercontent.com/your_image.png" alt="trajectory output" width="600"/>

- Red, blue, and green paths represent different people.
- IDs persist across frames.
- Video output includes real-time paths.

---

## üßÆ Core Logic & Math

### 1. Centroid Tracking

Given bounding boxes:
```
(x1, y1, x2, y2)
```

Centroid is calculated as:

```math
C_x = (x1 + x2) / 2  
C_y = (y1 + y2) / 2
```

Euclidean distance to previous centroids determines object association:

```math
D = \sqrt{(C_{x1} - C_{x2})^2 + (C_{y1} - C_{y2})^2}
```

---

## üíª Example Code Snippet

```python
from ultralytics import YOLO
import cv2

# Load YOLOv8 model
model = YOLO("yolov8n.pt")

# Read video
cap = cv2.VideoCapture("input_videos/sample_video.mp4")
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
fps = int(cap.get(5))

# Initialize output
out = cv2.VideoWriter("outputs/tracked_video.mp4", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

# Frame processing loop
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    results = model(frame)
    # Process results and draw paths...
    out.write(frame)

cap.release()
out.release()
```

---

## üìà Results & Evaluation

| Metric                  | Value |
|-------------------------|-------|
| Model Used              | YOLOv8n |
| Tracking FPS            | ~22   |
| Average Detection Accuracy | ~94% |
| Number of People Tracked | 3     |
| Output Video Length     | 1 minute |

---

## üì• Dataset

- Custom recorded 1-minute video.
- Contains at least **3 people crossing paths**.
- Resolution: 720p
- Format: `.mp4`

üìÅ Located in `input_videos/`.

---

## üß™ Testing

To test the notebook:

```bash
jupyter notebook notebooks/DSAI_352_Final_Project_Computer_Vision.ipynb
```

Or in Colab:

```python
from google.colab import drive
drive.mount('/content/drive')
```

---

## ‚úÖ Future Improvements

- [ ] Implement Deep SORT or ByteTrack for more robust ID matching.
- [ ] Add GUI or web interface for uploading video.
- [ ] Deploy as Flask or Streamlit app.
- [ ] Integrate pose estimation for richer tracking.

---

